The Model context protocol (aka MCP) is a way to provide tools and context to the LLM. From the MCP docs:

MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.

The Agents SDK has support for MCP. This enables you to use a wide range of MCP servers to provide tools to your Agents.

MCP servers
Currently, the MCP spec defines two kinds of servers, based on the transport mechanism they use:

stdio servers run as a subprocess of your application. You can think of them as running "locally".
HTTP over SSE servers run remotely. You connect to them via a URL.
You can use the MCPServerStdio and MCPServerSse classes to connect to these servers.

For example, this is how you'd use the official MCP filesystem server.


async with MCPServerStdio(
    params={
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-filesystem", samples_dir],
    }
) as server:
    tools = await server.list_tools()